{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes ingenuo Tarea 1\n",
    "### Equipo 11\n",
    "- Iñaki Fernandez Fiscal\n",
    "- Guillermo Arredondo Renero\n",
    "- Mauricio Vazquez Moran\n",
    "\n",
    "Este programa clasifica correos electrónicos como spam o ham utilizando el alrogítmo de bayes ingenuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "usePackage <- function(p) \n",
    "{\n",
    "  if (!is.element(p, installed.packages()[,1]))\n",
    "    install.packages(p, repos = \"\")\n",
    "  suppressPackageStartupMessages(require(p, character.only = TRUE, quietly  = TRUE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tm' was built under R version 3.6.3\"Warning message:\n",
      "\"package 'NLP' was built under R version 3.6.3\""
     ]
    }
   ],
   "source": [
    "usePackage('R.utils')\n",
    "usePackage('tm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "download.mails <- function(url, dir_name, file_name){\n",
    "\n",
    "  if (!file.exists(dir_name)) {\n",
    "    dir.create(dir_name)  \n",
    "  }\n",
    "  \n",
    "  download.file(url, destfile=file.path(dir_name, paste0(file_name,\".tar.bz2\")) )\n",
    "  bunzip2(file.path(dir_name, paste0(file_name,\".tar.bz2\")))\n",
    "  \n",
    "  untar(file.path(dir_name, paste0(file_name,\".tar\")), exdir = dir_name)\n",
    "  \n",
    "  if (file.exists(file.path(dir_name, paste0(file_name,\".tar\")))) {\n",
    "    file.remove(file.path(dir_name, paste0(file_name,\".tar\")))\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_name <- \"data\"\n",
    "file_name <- \"easy_ham_2\"\n",
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2\"\n",
    "file_name <- \"hard_ham\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2\"\n",
    "file_name <- \"spam_2\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los correos electrónicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hacemos una función que leea el mensaje del archivo que se le pase como parámetro\n",
    "# asumimos que el archivo contiene un correo\n",
    "\n",
    "lee_mensaje <- function(correo) {\n",
    "  fd <- file(correo, open = \"rt\") # regresa un lector de archivo\n",
    "  lineas <- readLines(fd, warn=FALSE) # lee linea por linea y genera un vector de cadenas de caracteres\n",
    "  close(fd)\n",
    "  mensaje <- lineas[seq(which(lineas == \"\")[1] + 1, length(lineas), 1)] # which trae indices del vector que cumplen condicion\n",
    "  return (paste(mensaje, collapse = \"\\n\")) # paste concatena sinser el primer caracter, collapse evita que sea vector y sea todo una cadena\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos variables con los directorios donde se encuentran los datos\n",
    "trayectoria_spam     <- file.path(dir_name, \"spam_2\")\n",
    "trayectoria_easyham  <- file.path(dir_name, \"easy_ham_2\")\n",
    "trayectoria_hardham  <- file.path(dir_name, \"hard_ham\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como spam\n",
    "archivos_correos_spam <- dir(trayectoria_spam)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_spam <- archivos_correos_spam[which(archivos_correos_spam!=\"cmds\")] #[1:250]\n",
    "\n",
    "# Aquí empieza la tarea\n",
    "# Dividir entre entrenamiento y prueba, muestras aleatorias de los archivos, unos para entrenar y otros para probarlo\n",
    "archivos_correos_spam <- archivos_correos_spam[sample(1:length(archivos_correos_spam))]\n",
    "archivos_correos_spam_training <- archivos_correos_spam[1:200]\n",
    "archivos_correos_spam_testing <- archivos_correos_spam[201:250]\n",
    "\n",
    "# cambiar a training_spam\n",
    "todo_spam <- sapply(archivos_correos_spam_training,\n",
    "                   function(p) lee_mensaje(file.path(trayectoria_spam, p)))\n",
    "                    \n",
    "todo_spam <- enc2utf8(todo_spam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham fácilmente identificables\n",
    "archivos_correos_easy_ham <- dir(trayectoria_easyham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_easy_ham <- archivos_correos_easy_ham[which(archivos_correos_easy_ham!=\"cmds\")] #[1:250]\n",
    "\n",
    "archivos_correos_easy_ham <- archivos_correos_easy_ham[sample(1:length(archivos_correos_easy_ham))]\n",
    "archivos_correos_easy_ham_training <- archivos_correos_easy_ham[1:200]\n",
    "archivos_correos_easy_ham_testing <- archivos_correos_easy_ham[201:250]\n",
    "\n",
    "todo_easy_ham <- sapply(archivos_correos_easy_ham_training,\n",
    "                    function(p) lee_mensaje(file.path(trayectoria_easyham, p)))\n",
    "\n",
    "todo_easy_ham <- enc2utf8(todo_easy_ham)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham fácilmente identificables\n",
    "archivos_correos_hard_ham <- dir(trayectoria_hardham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_hard_ham <- archivos_correos_hard_ham[which(archivos_correos_hard_ham!=\"cmds\")] #[1:250]\n",
    "\n",
    "archivos_correos_hard_ham <- archivos_correos_hard_ham[sample(1:length(archivos_correos_hard_ham))]\n",
    "archivos_correos_hard_ham_training <- archivos_correos_hard_ham[1:200]\n",
    "archivos_correos_hard_ham_testing <- archivos_correos_hard_ham[201:length(archivos_correos_hard_ham)]\n",
    "\n",
    "todo_hard_ham <- sapply(archivos_correos_hard_ham_training,\n",
    "                    function(p) lee_mensaje(file.path(trayectoria_hardham, p)))\n",
    "\n",
    "todo_hard_ham <- enc2utf8(todo_hard_ham)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de corpus y bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "obtiene_TermDocumentMatrix <- function (vector_correos) {\n",
    "  control <- list(stopwords = TRUE,\n",
    "                removePunctuation = TRUE,\n",
    "                removeNumbers = TRUE,\n",
    "                minDocFreq = 2)\n",
    "  corpus <- Corpus(VectorSource(vector_correos))\n",
    "  return(TermDocumentMatrix(corpus, control))\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "spam_TDM <- obtiene_TermDocumentMatrix(todo_spam)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento SPAM\n",
    "matriz_spam <- as.matrix(spam_TDM)\n",
    "\n",
    "conteos_spam <- rowSums(matriz_spam)\n",
    "df_spam <- data.frame(cbind(names(conteos_spam),\n",
    "                            as.numeric(conteos_spam)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_spam) <- c(\"terminos\", \"frecuencia\")\n",
    "df_spam$frecuencia <- as.numeric(df_spam$frecuencia)\n",
    "ocurrencias_spam <- sapply(1:nrow(matriz_spam),\n",
    "                          function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                          {\n",
    "                            length(which(matriz_spam[i, ] > 0)) / ncol(matriz_spam)\n",
    "                          })\n",
    "densidad_spam <- df_spam$frecuencia/sum(df_spam$frecuencia,na.rm = TRUE) #na.rm (remove na)\n",
    "\n",
    "df_spam <- transform(df_spam,\n",
    "                     densidad = densidad_spam,\n",
    "                     ocurrencias = ocurrencias_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>terminos</th><th scope=col>frecuencia</th><th scope=col>densidad</th><th scope=col>ocurrencias</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>acceptance  </td><td> 1          </td><td>1.777651e-05</td><td>0.005       </td></tr>\n",
       "\t<tr><td>accounts    </td><td> 5          </td><td>8.888257e-05</td><td>0.010       </td></tr>\n",
       "\t<tr><td>actual      </td><td> 4          </td><td>7.110605e-05</td><td>0.015       </td></tr>\n",
       "\t<tr><td>africa      </td><td> 2          </td><td>3.555303e-05</td><td>0.005       </td></tr>\n",
       "\t<tr><td>agencies    </td><td>14          </td><td>2.488712e-04</td><td>0.030       </td></tr>\n",
       "\t<tr><td>allowed     </td><td> 2          </td><td>3.555303e-05</td><td>0.010       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " terminos & frecuencia & densidad & ocurrencias\\\\\n",
       "\\hline\n",
       "\t acceptance   &  1           & 1.777651e-05 & 0.005       \\\\\n",
       "\t accounts     &  5           & 8.888257e-05 & 0.010       \\\\\n",
       "\t actual       &  4           & 7.110605e-05 & 0.015       \\\\\n",
       "\t africa       &  2           & 3.555303e-05 & 0.005       \\\\\n",
       "\t agencies     & 14           & 2.488712e-04 & 0.030       \\\\\n",
       "\t allowed      &  2           & 3.555303e-05 & 0.010       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| terminos | frecuencia | densidad | ocurrencias |\n",
       "|---|---|---|---|\n",
       "| acceptance   |  1           | 1.777651e-05 | 0.005        |\n",
       "| accounts     |  5           | 8.888257e-05 | 0.010        |\n",
       "| actual       |  4           | 7.110605e-05 | 0.015        |\n",
       "| africa       |  2           | 3.555303e-05 | 0.005        |\n",
       "| agencies     | 14           | 2.488712e-04 | 0.030        |\n",
       "| allowed      |  2           | 3.555303e-05 | 0.010        |\n",
       "\n"
      ],
      "text/plain": [
       "  terminos   frecuencia densidad     ocurrencias\n",
       "1 acceptance  1         1.777651e-05 0.005      \n",
       "2 accounts    5         8.888257e-05 0.010      \n",
       "3 actual      4         7.110605e-05 0.015      \n",
       "4 africa      2         3.555303e-05 0.005      \n",
       "5 agencies   14         2.488712e-04 0.030      \n",
       "6 allowed     2         3.555303e-05 0.010      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df_spam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "easy_ham_TDM <- obtiene_TermDocumentMatrix(todo_easy_ham)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento easy ham\n",
    "matriz_easy_ham <- as.matrix(easy_ham_TDM)\n",
    "\n",
    "conteos_easy_ham <- rowSums(matriz_easy_ham)\n",
    "df_easy_ham <- data.frame(cbind(names(conteos_easy_ham),\n",
    "                            as.numeric(conteos_easy_ham)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_easy_ham) <- c(\"terminos\", \"frecuencia\")\n",
    "df_easy_ham$frecuencia <- as.numeric(df_easy_ham$frecuencia)\n",
    "ocurrencias_easy_ham <- sapply(1:nrow(matriz_easy_ham),\n",
    "                           function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                           {\n",
    "                             length(which(matriz_easy_ham[i, ] > 0)) / ncol(matriz_easy_ham)\n",
    "                           })\n",
    "densidad_easy_ham <- df_easy_ham$frecuencia/sum(df_easy_ham$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_easy_ham <- transform(df_easy_ham,\n",
    "                     densidad = densidad_easy_ham,\n",
    "                     ocurrencias = ocurrencias_easy_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>terminos</th><th scope=col>frecuencia</th><th scope=col>densidad</th><th scope=col>ocurrencias</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>administrator</td><td> 3           </td><td>1.029760e-04 </td><td>0.015        </td></tr>\n",
       "\t<tr><td>august       </td><td>17           </td><td>5.835307e-04 </td><td>0.060        </td></tr>\n",
       "\t<tr><td>beeping      </td><td> 1           </td><td>3.432534e-05 </td><td>0.005        </td></tr>\n",
       "\t<tr><td>brady        </td><td> 5           </td><td>1.716267e-04 </td><td>0.025        </td></tr>\n",
       "\t<tr><td>computing    </td><td> 3           </td><td>1.029760e-04 </td><td>0.015        </td></tr>\n",
       "\t<tr><td>department   </td><td> 7           </td><td>2.402773e-04 </td><td>0.025        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " terminos & frecuencia & densidad & ocurrencias\\\\\n",
       "\\hline\n",
       "\t administrator &  3            & 1.029760e-04  & 0.015        \\\\\n",
       "\t august        & 17            & 5.835307e-04  & 0.060        \\\\\n",
       "\t beeping       &  1            & 3.432534e-05  & 0.005        \\\\\n",
       "\t brady         &  5            & 1.716267e-04  & 0.025        \\\\\n",
       "\t computing     &  3            & 1.029760e-04  & 0.015        \\\\\n",
       "\t department    &  7            & 2.402773e-04  & 0.025        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| terminos | frecuencia | densidad | ocurrencias |\n",
       "|---|---|---|---|\n",
       "| administrator |  3            | 1.029760e-04  | 0.015         |\n",
       "| august        | 17            | 5.835307e-04  | 0.060         |\n",
       "| beeping       |  1            | 3.432534e-05  | 0.005         |\n",
       "| brady         |  5            | 1.716267e-04  | 0.025         |\n",
       "| computing     |  3            | 1.029760e-04  | 0.015         |\n",
       "| department    |  7            | 2.402773e-04  | 0.025         |\n",
       "\n"
      ],
      "text/plain": [
       "  terminos      frecuencia densidad     ocurrencias\n",
       "1 administrator  3         1.029760e-04 0.015      \n",
       "2 august        17         5.835307e-04 0.060      \n",
       "3 beeping        1         3.432534e-05 0.005      \n",
       "4 brady          5         1.716267e-04 0.025      \n",
       "5 computing      3         1.029760e-04 0.015      \n",
       "6 department     7         2.402773e-04 0.025      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df_easy_ham)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hard_ham_TDM <- obtiene_TermDocumentMatrix(todo_hard_ham)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento easy ham\n",
    "matriz_hard_ham <- as.matrix(hard_ham_TDM)\n",
    "\n",
    "conteos_hard_ham <- rowSums(matriz_hard_ham)\n",
    "df_hard_ham <- data.frame(cbind(names(conteos_hard_ham),\n",
    "                            as.numeric(conteos_hard_ham)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_hard_ham) <- c(\"terminos\", \"frecuencia\")\n",
    "df_hard_ham$frecuencia <- as.numeric(df_hard_ham$frecuencia)\n",
    "ocurrencias_hard_ham <- sapply(1:nrow(matriz_hard_ham),\n",
    "                           function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                           {\n",
    "                             length(which(matriz_hard_ham[i, ] > 0)) / ncol(matriz_hard_ham)\n",
    "                           })\n",
    "densidad_hard_ham <- df_hard_ham$frecuencia/sum(df_hard_ham$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_hard_ham <- transform(df_hard_ham,\n",
    "                     densidad = densidad_hard_ham,\n",
    "                     ocurrencias = ocurrencias_hard_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>terminos</th><th scope=col>frecuencia</th><th scope=col>densidad</th><th scope=col>ocurrencias</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>aac         </td><td>  4         </td><td>1.706499e-05</td><td>0.015       </td></tr>\n",
       "\t<tr><td>ability     </td><td> 30         </td><td>1.279874e-04</td><td>0.100       </td></tr>\n",
       "\t<tr><td>able        </td><td> 51         </td><td>2.175786e-04</td><td>0.170       </td></tr>\n",
       "\t<tr><td>aboutcom    </td><td>  1         </td><td>4.266248e-06</td><td>0.005       </td></tr>\n",
       "\t<tr><td>access      </td><td>112         </td><td>4.778198e-04</td><td>0.235       </td></tr>\n",
       "\t<tr><td>accessing   </td><td>  5         </td><td>2.133124e-05</td><td>0.020       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " terminos & frecuencia & densidad & ocurrencias\\\\\n",
       "\\hline\n",
       "\t aac          &   4          & 1.706499e-05 & 0.015       \\\\\n",
       "\t ability      &  30          & 1.279874e-04 & 0.100       \\\\\n",
       "\t able         &  51          & 2.175786e-04 & 0.170       \\\\\n",
       "\t aboutcom     &   1          & 4.266248e-06 & 0.005       \\\\\n",
       "\t access       & 112          & 4.778198e-04 & 0.235       \\\\\n",
       "\t accessing    &   5          & 2.133124e-05 & 0.020       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| terminos | frecuencia | densidad | ocurrencias |\n",
       "|---|---|---|---|\n",
       "| aac          |   4          | 1.706499e-05 | 0.015        |\n",
       "| ability      |  30          | 1.279874e-04 | 0.100        |\n",
       "| able         |  51          | 2.175786e-04 | 0.170        |\n",
       "| aboutcom     |   1          | 4.266248e-06 | 0.005        |\n",
       "| access       | 112          | 4.778198e-04 | 0.235        |\n",
       "| accessing    |   5          | 2.133124e-05 | 0.020        |\n",
       "\n"
      ],
      "text/plain": [
       "  terminos  frecuencia densidad     ocurrencias\n",
       "1 aac         4        1.706499e-05 0.015      \n",
       "2 ability    30        1.279874e-04 0.100      \n",
       "3 able       51        2.175786e-04 0.170      \n",
       "4 aboutcom    1        4.266248e-06 0.005      \n",
       "5 access    112        4.778198e-04 0.235      \n",
       "6 accessing   5        2.133124e-05 0.020      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df_hard_ham)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de probabilidad a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "a_posteriori <- function(trayectoria, df_entrenamiento, a_priori = 0.5, c = 1e-6)\n",
    "{\n",
    "  mensaje <- lee_mensaje(trayectoria)\n",
    "  mensaje <- enc2utf8(mensaje)\n",
    "  mensaje_TDM <- obtiene_TermDocumentMatrix(mensaje)\n",
    "  conteos_mensaje <- rowSums(as.matrix(mensaje_TDM))\n",
    "\n",
    "  # Encuentra palabras en data frame de entrenamiento\n",
    "  mensaje_palabras_comunes <- intersect(names(conteos_mensaje), df_entrenamiento$terminos)\n",
    "  \n",
    "  # Ahora sólo aplicamos la clasificación Bayes ingenuo\n",
    "  if(length(mensaje_palabras_comunes) < 1)\n",
    "  {\n",
    "    #return(a_priori * c ^ (length(conteos_mensaje)))\n",
    "    return(log(a_priori) + (length(conteos_mensaje)) *log(c))\n",
    "  }\n",
    "  else\n",
    "  {\n",
    "    probabilidades_palabras_comunes <- df_entrenamiento$densidad[match(mensaje_palabras_comunes, df_entrenamiento$terminos)]\n",
    "    #return(a_priori * prod(probabilidades_palabras_comunes) * c ^ (length(conteos_mensaje) - length(mensaje_palabras_comunes)))\n",
    "    return(log(a_priori) + sum(log(probabilidades_palabras_comunes)) + log(c) * (length(conteos_mensaje) - length(mensaje_palabras_comunes)))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'ramify' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\memit\\AppData\\Local\\Temp\\RtmpuSvaSo\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"ramify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ramify' was built under R version 3.6.3\"\n",
      "Attaching package: 'ramify'\n",
      "\n",
      "The following object is masked from 'package:graphics':\n",
      "\n",
      "    clip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(ramify)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación (modificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "clasifica_spam_max <- function(trayectoria, archivos) {\n",
    "\n",
    "  spam_prueba <- sapply(archivos,\n",
    "                             function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_spam))\n",
    "  ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_easy_ham))\n",
    "  hard_ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_hard_ham))\n",
    "                                \n",
    "  x <- matrix(c(ham_prueba, hard_ham_prueba, spam_prueba), nrow=length(ham_prueba), ncol=3)\n",
    "  return(as.factor(argmax(x)))\n",
    "                        \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "clasifica_spam <- function(trayectoria, archivos) {\n",
    "\n",
    "  hard_ham_spam_prueba <- sapply(archivos,\n",
    "                             function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_spam))\n",
    "  hard_ham_ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_hard_ham))\n",
    "  \n",
    "  return (ifelse(hard_ham_spam_prueba > hard_ham_ham_prueba,\n",
    "                        TRUE,\n",
    "                        FALSE))\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con 2 var (hard ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham dificlmente identificables\n",
    "archivos_correos_easy_ham_2 <- dir(trayectoria_easyham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_easy_ham_2 <- archivos_correos_easy_ham[which(archivos_correos_easy_ham!=\"cmds\")]\n",
    "archivos_correos_easy_ham_2 <- archivos_correos_easy_ham_2[sample(1:length(archivos_correos_easy_ham_2))]\n",
    "archivos_correos_easy_ham_2 <- archivos_correos_easy_ham_2[201:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hard_ham_res <- clasifica_spam(trayectoria_hardham, archivos_correos_hard_ham_testing)\n",
    "easy_ham_res <- clasifica_spam(trayectoria_easyham, archivos_correos_easy_ham_2)\n",
    "spam_res     <- clasifica_spam(trayectoria_spam,    archivos_correos_spam_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Mode   FALSE    TRUE \n",
       "logical      40      10 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Mode   FALSE    TRUE \n",
       "logical       1      49 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Mode   FALSE    TRUE \n",
       "logical      45       5 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(easy_ham_res)\n",
    "summary(spam_res)\n",
    "summary(hard_ham_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "easy_ham_res <- clasifica_spam_max(trayectoria_easyham, archivos_correos_easy_ham_testing)\n",
    "hard_ham_res <- clasifica_spam_max(trayectoria_hardham, archivos_correos_hard_ham_testing)\n",
    "spam_res     <- clasifica_spam_max(trayectoria_spam,    archivos_correos_spam_testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 50"
      ],
      "text/latex": [
       "\\textbf{1:} 50"
      ],
      "text/markdown": [
       "**1:** 50"
      ],
      "text/plain": [
       " 1 \n",
       "50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>42</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>4</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 4\n",
       "\\item[2] 42\n",
       "\\item[3] 4\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   42\n",
       ":   423\n",
       ":   4\n",
       "\n"
      ],
      "text/plain": [
       " 1  2  3 \n",
       " 4 42  4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>2</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>47</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 2\n",
       "\\item[2] 1\n",
       "\\item[3] 47\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   22\n",
       ":   13\n",
       ":   47\n",
       "\n"
      ],
      "text/plain": [
       " 1  2  3 \n",
       " 2  1 47 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(easy_ham_res)\n",
    "summary(hard_ham_res)\n",
    "summary(spam_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones Generales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Entrenamiento con easy-ham y spam:** \n",
    "El modelo clasifica de manera perfecta el easy ham, pero se debe a que entrenamos con easy ham. Es muy bueno para calcular el easy ham debido a que son los datos que le presentamos al modelo. Lo correcto seria presentar una muestra estratificada o que tuviera tanto hard ham como easy ham. Con una muestra donde tuviera 80% de easy ham + 80% de hard ham haría que tuviera una mayor precisión. Sin embargo, no es tan malo para predecir Spam, pues tiene un ~5% de error para el de dataset de Spam, pero para hard ham tiene ~45% de error. Es casi lo equivalente a un volado...\n",
    "2. **Entrenamiento con hard-ham y spam:**\n",
    "Este entrenamiento resulta en una aparente mejora en comparación al entrenamiento con easy-ham, pues la eficiencia de hard-ham mejora, evidente y notablemente; sin embargo, es importante darnos cuenta que esto se debe a que ahora entrenamos con esa muestra, por lo que tiene muchísima más información con la cual comparar; lamentablemente esto resulta en un decaimiento esperado del rendimiento de easy-ham. No obstante, hay que notar que el porcentaje de error con la prueba de easy-ham es mucho mejor que en el caso 1, siendo ~70%. Además, detecta casi perfectamente a los spam (en algunos casos perfectamente); esto nos indica un mejor aprendizaje de los ham's en general en comparación al entrenamiento con easy-ham. \n",
    "3. **Comparación con 3 variables en matriz:**\n",
    "Ahora observamos dos cosas importantes: en primer lugar, el ajuste general de entrenamiento resulta satisfactorio en proporciones mucho más significantes que en los dos casos anteriores, pues vemos que logra identificar con gran precisión los tres conjuntos de características. En segundo lugar, podemos observar una relación interesante en el hecho de que las dos clases, aparentemente más separadas (easy-ham y spam) las logra clasificar casi perfectamente ( ~94%-98% ), al mismo tiempo que en el caso de la variable que intersecta entre ambas (hard-ham), la precisión de detección de spam se mantiene estable ( ~92%-94% ).\n",
    "Por último, consideramos que podríamos verificar mejor el modelo al dar muestras que se acerquen más al 80-20 para cada variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
